{% extends "layout.html" %}

{% block jumbotron %}
<div class="jumbotron">
   <h1>Python Cheat Sheet</h1>
   <p>Cheat sheet of Python. Some concurrency concept for Python programmer need to know.</p>
</div>
{% endblock %}

{% block body %}
<div class="row col-md-4 col-xs-12">

<h3>Create a Thread Via threading</h3>
<pre class="code python">
&gt;&gt;&gt; from threading import Thread
&gt;&gt;&gt; class Worker(Thread):
...   def __init__(self, id):
...     super(Worker, self).__init__()
...     self._id = id
...   def run(self):
...     print "I am worker %d" % self._id
... 
&gt;&gt;&gt; t1 = Worker(1)
&gt;&gt;&gt; t2 = Worker(2)
&gt;&gt;&gt; t1.start(); t2.start()
I am worker 1
I am worker 2

# using function could be more flexible
&gt;&gt;&gt; def Worker(worker_id):
...   print "I am worker %d" % worker_id
... 
&gt;&gt;&gt; from threading import Thread
&gt;&gt;&gt; t1 = Thread(target=Worker, args=(1,))
&gt;&gt;&gt; t2 = Thread(target=Worker, args=(2,))
&gt;&gt;&gt; t1.start()
I am worker 1
I am worker 2
</pre>
<h3>Thread Performance Problem - GIL</h3>
<pre class="code python">
# GIL - Global Interpreter Lock
# see: <a href="http://www.slideshare.net/emayssat/pythonunderstanding-gil">Ungerstanging the Python GIL</a>
&gt;&gt;&gt; from threading import Thread
&gt;&gt;&gt; def profile(func):
...   def wrapper(*args, **kwargs):
...     import time
...     start = time.time()
...     func(*args, **kwargs)
...     end   = time.time()
...     print end - start
...   return wrapper
...
&gt;&gt;&gt; @profile
... def nothread():
...   fib(35)
...   fib(35)
... 
&gt;&gt;&gt; @profile
... def hasthread():
...   t1=Thread(target=fib, args=(35,))
...   t2=Thread(target=fib, args=(35,))
...   t1.start(); t2.start()
...   t1.join(); t2.join()
... 
&gt;&gt;&gt; nothread()
9.51164007187
&gt;&gt;&gt; hasthread()
11.3131771088
# !Thread get bad Performance
# since cost on context switch
</pre>
<h3>Consumer and Producer Architecture</h3>
<pre class="code python">
# This architecture make concurrency easy
&gt;&gt;&gt; from threading import Thread
&gt;&gt;&gt; from Queue import Queue
&gt;&gt;&gt; from random import random
&gt;&gt;&gt; import time
&gt;&gt;&gt; q = Queue()
&gt;&gt;&gt; def fib(n):
...   if n&lt;=2:
...     return 1
...   return fib(n-1)+fib(n-2)
... 
&gt;&gt;&gt; def producer():
...   while True:
...     wt = random()*5
...     time.sleep(wt)
...     q.put((fib,35))
... 
&gt;&gt;&gt; def consumer():
...   while True:
...     task,arg = q.get()
...     print task(arg)
...     q.task_done()
... 
&gt;&gt;&gt; t1 = Thread(target=producer)
&gt;&gt;&gt; t2 = Thread(target=consumer)
&gt;&gt;&gt; t1.start();t2.start()
</pre>


<h3>Thread Pool Templeate</h3>
<pre class="code python">
# producer and consumer architecture
from Queue import Queue
from threading import Thread

class Worker(Thread):
   def __init__(self,queue):
      super(Worker, self).__init__()
      self._q = queue
      self.daemon = True
      self.start()
   def run(self):
      while True:
         f,args,kwargs = self._q.get()
         try:
            print f(*args, **kwargs)
         except Exception as e:
            print e
         self._q.task_done()

class ThreadPool(object):
   def __init__(self, num_t=5):
      self._q = Queue(num_t)
      # Create Worker Thread
      for _ in range(num_t):
         Worker(self._q) 
   def add_task(self,f,*args,**kwargs):
      self._q.put((f, args, kwargs))
   def wait_complete(self):
      self._q.join()
      
def fib(n):
   if n &lt;= 2:
      return 1
   return fib(n-1)+fib(n-2) 

if __name__ == '__main__':
   pool = ThreadPool()
   for _ in range(3):
      pool.add_task(fib,35)
   pool.wait_complete()
</pre>

<h3>Using multiprocessing ThreadPool</h3>
<pre class="code python">
# ThreadPool is not in python doc
&gt;&gt;&gt; from multiprocessing.pool import \
...      ThreadPool
&gt;&gt;&gt; pool = ThreadPool(5)
&gt;&gt;&gt; pool.map(lambda x: x**2, range(5))
[0, 1, 4, 9, 16]

# compare with map performance
# pool will get bad result since GIL
import time
from multiprocessing.pool import \
     ThreadPool

pool = ThreadPool(10)
def profile(func):
    def wrapper(*args, **kwargs):
       print func.__name__ 
       s = time.time() 
       func(*args, **kwargs)
       e = time.time()
       print "cost: {0}".format(e-s) 
    return wrapper

@profile
def pool_map():
    res = pool.map(lambda x:x**2, 
                   range(999999))

@profile
def ordinary_map():
    res = map(lambda x:x**2, 
              range(999999))

pool_map()
ordinary_map()

# output:
# pool_map
# cost: 0.562669038773
# ordinary_map
# cost: 0.38525390625
</pre>

<h3>Synchronization Options in "threading"</h3>
<pre class="code python">
# sync primitive
threading.Lock

# reentry sync primitive
# can use it to implement monitor
threading.RLock

# counter-based sync primitive
threading.Semaphore
threading.BoundedSemaphore

# common used: signaling or barrier
threading.Event

# combination of locking and signaling
threading.Condition
</pre>

<h3>Simple synchronization primitive - Mutex lock</h3>
<pre class="code python">
&gt;&gt;&gt; from threading import Thread
&gt;&gt;&gt; from threading import Lock
&gt;&gt;&gt; lock = Lock()
&gt;&gt;&gt; def getlock(id):
...   lock.acquire()
...   print "task{0} get".format(id)
...   lock.release()
... 
&gt;&gt;&gt; t1=Thread(target=getlock,args=(1,))
&gt;&gt;&gt; t2=Thread(target=getlock,args=(2,))
&gt;&gt;&gt; t1.start();t2.start()
task1 get
task2 get

# using lock manager
&gt;&gt;&gt; def getlock(id):
...   with lock:
...     print "task%d get" % id
... 
&gt;&gt;&gt; t1=Thread(target=getlock,args=(1,))
&gt;&gt;&gt; t2=Thread(target=getlock,args=(2,))
&gt;&gt;&gt; t1.start();t2.start()
task1 get
task2 get
</pre>

<h3>Deadlock - happen when more than one mutex lock</h3>
<pre class="code python">
# deadlock example as below
&gt;&gt;&gt; import threading
&gt;&gt;&gt; import time
&gt;&gt;&gt; lock1 = threading.Lock()
&gt;&gt;&gt; lock2 = threading.Lock()
&gt;&gt;&gt; def task1():
...   with lock1:
...     print "get lock1"
...     time.sleep(3)
...     with lock2:
...       print "No deadlock"
... 
&gt;&gt;&gt; def task2():
...   with lock2:
...     print "get lock2"
...     with lock1:
...       print "No deadlock"
... 
&gt;&gt;&gt; t1=threading.Thread(target=task1)
&gt;&gt;&gt; t2=threading.Thread(target=task2)
&gt;&gt;&gt; t1.start();t2.start()
get lock1
 get lock2

&gt;&gt;&gt; t1.isAlive()
True
&gt;&gt;&gt; t2.isAlive()
True
</pre>
</div>

<div class="row col-md-4 col-xs-12">

<h3>Implement "Monitor" Via RLock</h3>
<pre class="code python">
# ref:<a href="http://www.slideshare.net/dabeaz/an-introduction-to-python-concurrency?related=1"> SlideShare - David Beazley</a>
# example.py
from threading import Thread
from threading import RLock
import time

class monitor(object):
   lock = RLock()
   def foo(self,tid):
      with monitor.lock:
         print "%d in foo" % tid
         time.sleep(5)
         self.ker(tid)

   def ker(self,tid):
      with monitor.lock:
         print "%d in ker" % tid
m = monitor()
def task1(id):
   m.foo(id)

def task2(id):
   m.ker(id)      

t1 = Thread(target=task1,args=(1,))
t2 = Thread(target=task2,args=(2,))
t1.start()
t2.start()
t1.join()
t2.join()

# bash&gt; python example.py 
# 1 in foo
# 1 in ker
# 2 in ker
</pre>

<h3>Using Semaphore to control resource</h3>
<pre class="code python">
# example.py
from threading import Thread
from threading import Semaphore
from random    import random
import time

# limit resource to 3
sema = Semaphore(3)
def foo(tid):
   with sema:
      print "%d acquire sema" % tid
      wt = random()*5
      time.sleep(wt)
   print "%d release sema" % tid

threads = []
for _t in range(5):
   t = Thread(target=foo,args=(_t,))
   threads.append(t)
   t.start()
for _t in threads:
   _t.join()

# bash&gt; python example.py 
# 0 acquire sema
# 1 acquire sema
# 2 acquire sema
# 0 release sema
#  3 acquire sema
# 2 release sema
#  4 acquire sema
# 1 release sema
# 4 release sema
# 3 release sema
</pre>

<h3>Using Semaphore to signal other to task work</h3>
<pre class="code python">
# example.py
from threading import Thread
from threading import Semaphore
import time

sema = Semaphore(0)
def task1():
   time.sleep(3)
   print "signaling task2 to work"
   sema.release()

def task2():
   sema.acquire()
   print "task1 call me to work"

t1 = Thread(target=task1)
t2 = Thread(target=task2)
t2.start()
t1.start()
t2.join()
t1.join()

# bash&gt; python example.py
# signaling task2 to work
# task1 call me to work
</pre>


<h3>Using event to ensure some task has done</h3>
<pre class="code python">
# example.py
from threading import Thread
from threading import Event
import time

e = Event()

def worker(id):
   print "%d wait event" % id
   e.wait()
   print "%d get event set" % id

t1=Thread(target=worker,args=(1,))
t2=Thread(target=worker,args=(2,))
t3=Thread(target=worker,args=(3,))
t1.start()
t2.start()
t3.start()
# wait sleep task(event) happen
time.sleep(3)
e.set()
# bash&gt; python example.py 
# 1 wait event
# 2 wait event
# 3 wait event
# 2 get event set
#  3 get event set
# 1 get event set
</pre>


<h3>Implement a thread-safe priority queue via condition</h3>

<pre class="code python">
# ex.py
import threading
import heapq
import time
import random

class PriorityQueue(object):
   def __init__(self):
      self._q = []
      self._count = 0
      self._cv = threading.Condition()

   def __str__(self):
      return str(self._q)
   def __repr__(self):
      return self._q

   def put(self, item, priority):
      with self._cv:
         heapq.heappush(
            self._q,
            (-priority,self._count,item))
         self._count += 1
         self._cv.notify()
   def pop(self):
      with self._cv:
         while len(self._q) == 0:
            print("wait...")
            self._cv.wait()
         ret = heapq.heappop(self._q)[-1]
         return ret

priq = PriorityQueue()
def producer():
   while True:
      print(priq.pop())

def consumer():
   while True:
      time.sleep(3)
      print("consumer put value")
      priority = random.random()
      priq.put(priority,priority*10)

for _ in range(3):
   priority = random.random()
   priq.put(priority,priority*10)

t1=threading.Thread(target=producer)
t2=threading.Thread(target=consumer)
t1.start();t2.start()
t1.join();t2.join()

# bash&gt; python3 ex.py
# 0.6657491871045683
# 0.5278797439991247
# 0.20990624606296315
# wait...
# consumer put value
# 0.09123101305407577
# wait...
</pre>

<h3>Multiprocessing - Solving GIL Problem Via Processes</h3>
<pre class="code python">
# see: <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing</a>
&gt;&gt;&gt; from multiprocessing import Pool
&gt;&gt;&gt; def fib(n):
...   if n &gt;= 2:
...     return 1
...   return fib(n-1)+fib(n-2)
... 
&gt;&gt;&gt; def profile(func):
...   def wrapper(*args, **kwargs):
...     import time
...     start = time.time()
...     func(*args, **kwargs)
...     end   = time.time()
...     print end - start
...   return wrapper
... 
&gt;&gt;&gt; @profile
... def nomultiprocess():
...   map(fib,[35]*5)
... 
&gt;&gt;&gt; @profile
... def hasmultiprocess():
...   pool = Pool(5)
...   pool.map(fib,[35]*5)
... 
&gt;&gt;&gt; nomultiprocess()
23.8454811573
&gt;&gt;&gt; hasmultiprocess()
13.2433719635
</pre>

<h3>Custom multiprocessing map</h3>
<pre class="code python">
# ref: <a href="http://stackoverflow.com/questions/3288595/multiprocessing-using-pool-map-on-a-function-defined-in-a-class">stackoverflow</a>
from multiprocessing import Process, Pipe
from itertools import izip

def spawn(f):
    def fun(pipe,x):
        pipe.send(f(x))
        pipe.close()
    return fun

def parmap(f,X):
    pipe=[Pipe() for x in X]
    proc=[Process(target=spawn(f), 
          args=(c,x)) 
          for x,(p,c) in izip(X,pipe)]
    [p.start() for p in proc]
    [p.join() for p in proc]
    return [p.recv() for (p,c) in pipe]

print parmap(lambda x:x**x,range(1,5))
# output:
# [1, 4, 27, 256]
</pre>

</div>

<div class="row col-md-4 col-xs-12">

<h3>Simple round-robin Scheduler</h3>
<pre class="code python">
&gt;&gt;&gt; def fib(n):
...   if n &lt;= 2:
...     return 1
...   return fib(n-1)+fib(n-2)
... 
&gt;&gt;&gt; def gen_fib(n):
...   for _ in range(1,n+1):
...     yield fib(_)
...
&gt;&gt;&gt; t=[gen_fib(5),gen_fib(3)]
&gt;&gt;&gt; from collections import deque
&gt;&gt;&gt; tasks = deque()
&gt;&gt;&gt; tasks.extend(t)
&gt;&gt;&gt; def run(tasks):
...   while tasks:
...     try:
...       task = tasks.popleft()
...       print task.next()
...       tasks.append(task)
...     except StopIteration:
...       print "done"
... 
&gt;&gt;&gt; run(tasks)
1
1
1
1
2
2
3
done
5
done
</pre>
<h3>Simple round-robin Scheduler with blocking function</h3>
<pre class="code python">
# ref: <a href="https://www.youtube.com/watch?v=MCs5OvhV9S4">PyCon 2015 - David Beazley</a>
import socket
from select import select
from collections import deque

tasks  = deque()
r_wait = {}
s_wait = {}

def fib(n):
   if n &lt;= 2:
      return 1
   return fib(n-1)+fib(n-2)

def run():
   while any([tasks,r_wait,s_wait]):
      while not tasks:
         # polling
         rr, sr, _ = select(r_wait, 
                        s_wait, {})
         for _ in rr:
            tasks.append(r_wait.pop(_))
         for _ in sr:
            tasks.append(s_wait.pop(_))
      try:
         task = tasks.popleft()
         why,what = task.next()
         if why == 'recv':
            r_wait[what] = task
         elif why == 'send':
            s_wait[what] = task
         else:
            raise RuntimeError
      except StopIteration:
         pass
def fib_server():
   sock = socket.socket(
         socket.AF_INET,
         socket.SOCK_STREAM)
   sock.setsockopt(
         socket.SOL_SOCKET,
         socket.SO_REUSEADDR,1)
   sock.bind(('localhost',5566))
   sock.listen(5)
   while True:
      yield 'recv', sock
      c, a = sock.accept()
      tasks.append(fib_handler(c))
      
def fib_handler(client):
   while True:
      yield 'recv', client
      req  = client.recv(1024)
      if not req:
         break
      resp = fib(int(req))
      yield 'send', client
      client.send(str(resp)+'\n')
   client.close()

tasks.append(fib_server())
run()
# bash1&gt; nc loalhost 5566
# 20
# 6765
# bash2&gt; nc localhost 5566 
# 10
# 55
</pre>

<h3>PoolExecutor</h3>
<pre class="code python">
# python2.x is module futures on PyPI
# new in Python3.2
&gt;&gt;&gt; from concurrent.futures import \
...     ThreadPoolExecutor
&gt;&gt;&gt; def fib(n):
...     if n&lt;=2:
...         return 1
...     return fib(n-1) + fib(n-2)
...
&gt;&gt;&gt; with ThreadPoolExecutor(3) as e:
...     res= e.map(fib,[1,2,3,4,5])
...     for _ in res:
...         print(_, end=' ')
... 
1 1 2 3 5 &gt;&gt;&gt; 
# result is generator?!
&gt;&gt;&gt; with ThreadPoolExecutor(3) as e:
...   res = e.map(fib, [1,2,3])
...   inspect.isgenerator(res)
... 
True

# demo GIL 
import concurrent.futures as cf
import time

def fib(n):
    if n &lt;= 2:
        return 1
    return fib(n-1) + fib(n-2)

def thread():
    s = time.time()
    with cf.ThreadPoolExecutor(2) as e:
        res = e.map(fib, [35]*2)
        for _ in res:
            print(_)
    e = time.time()
    print("thread cost: {}".format(e-s))

def process():
    s = time.time()
    with cf.ProcessPoolExecutor(2) as e:
        res = e.map(fib, [35]*2)
        for _ in res:
            print(_)
    e = time.time()
    print("pocess cost: {}".format(e-s))


# bash&gt; python3 -i test.py 
&gt;&gt;&gt; thread()
9227465
9227465
thread cost: 12.550225019454956
&gt;&gt;&gt; process()
9227465
9227465
pocess cost: 5.538189888000488
</pre>

<h3>What "with ThreadPoolExecutor" doing?</h3>
<pre class="code python">
import concurrent.futures as cf

def fib(n):
    if n &lt;= 2:
        return 1
    return fib(n-1) + fib(n-2)

with cf.ThreadPoolExecutor(3) as e:
    fut = e.submit(fib, 30)
    res = fut.result()
    print(res)

# equal to
e = cf.ThreadPoolExecutor(3)
fut = e.submit(fib, 30)
fut.result()
e.shutdown(wait=True)
print(res)

# bash&gt; python3 test.py 
# 832040
# 832040
</pre>

<h3>Future object</h3>
<pre class="code python">
# future: deferred computation
# add_done_callback
import concurrent.futures as cf

def fib(n):
    if n &lt;= 2:
        return 1
    return fib(n-1) + fib(n-2)

def handler(future):
    res = future.result()
    print("res: {}".format(res))

def thread_v1():
    with cf.ThreadPoolExecutor(3) as e:
        for _ in range(3):
            f = e.submit(fib, 30+_)
            f.add_done_callback(handler)
    print("end")

def thread_v2():
    to_do = []
    with cf.ThreadPoolExecutor(3) as e:
        for _ in range(3):
            fut = e.submit(fib, 30+_)
            to_do.append(fut)
        for _f in cf.as_completed(to_do):
            res = _f.result()
            print("res: {}".format(res))
    print("end")

# bash&gt; python3 -i test.py 
&gt;&gt;&gt; thread_v1()
res: 832040
res: 1346269
res: 2178309
end
&gt;&gt;&gt; thread_v2()
res: 832040
res: 1346269
res: 2178309
end
</pre>

<h3>Future error handling</h3>
<pre class="code python">
import concurrent.futures as cf

def spam():
    raise RuntimeError

def handler(future):
    print("callback handler")
    try:
        res = future.result()
    except RuntimeError:
        print("get RuntimeError")

def thread_spam():
    with cf.ThreadPoolExecutor(2) as e:
        f = e.submit(spam)
        f.add_done_callback(handler)

# bash&gt; python -i test.py
&gt;&gt;&gt; thread_spam()
callback handler
get RuntimeError
</pre>

</div>
{% endblock %}

{% block script %}
{{ super() }}

{% endblock %}
